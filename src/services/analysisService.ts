import { AnalysisResult, BulkAnalysisJob } from '@/types'
import { ParserRegistry } from './parsing/ParserRegistry'

export class AnalysisService {
  private static readonly API_BASE = '/api'

  static async analyzeJob(jobUrl: string, jobData?: {title: string, company: string, description?: string, location?: string, remoteFlag?: boolean, postedAt?: Date}): Promise<AnalysisResult> {
    // If job data is not provided, extract it first
    if (!jobData) {
      try {
        const extracted = await this.extractJobData(jobUrl);
        jobData = {
          title: extracted.title,
          company: extracted.company,
          description: '', // We don't have description from basic extraction
          location: extracted.location,
          remoteFlag: extracted.remoteFlag,
          postedAt: extracted.postedAt
        };
      } catch (error) {
        console.warn('Job data extraction failed:', error)
        
        // If extraction fails, use fallback data and trigger learning
        jobData = {
          title: 'Unknown Position',
          company: 'Unknown Company',
          description: '',
          location: undefined,
          remoteFlag: false,
          postedAt: undefined
        };

        // Proactively trigger learning for failed parsing
        this.triggerLearningForFailure(jobUrl, jobData, error instanceof Error ? error : new Error(String(error))).catch(learningError => {
          console.warn('Learning trigger failed:', learningError)
        })
      }
    }

    const requestBody = { 
      url: jobUrl,
      title: jobData?.title,
      company: jobData?.company,
      description: jobData?.description || '',
      location: jobData?.location,
      remoteFlag: jobData?.remoteFlag,
      postedAt: jobData?.postedAt
    };

    console.log('üöÄ AnalysisService: Making API call to /analyze', {
      url: jobUrl.substring(0, 50) + '...',
      apiBase: this.API_BASE,
      requestBody
    });

    const response = await fetch(`${this.API_BASE}/analyze`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(requestBody),
    })

    console.log('üì° AnalysisService: Response received', {
      status: response.status,
      statusText: response.statusText,
      ok: response.ok,
      headers: {
        contentType: response.headers.get('content-type'),
        contentLength: response.headers.get('content-length')
      }
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('‚ùå AnalysisService: API error response:', errorText);
      throw new Error(`Analysis failed: ${response.statusText} - ${errorText}`)
    }

    let result;
    try {
      result = await response.json();
    } catch (parseError) {
      console.error('‚ùå AnalysisService: Failed to parse JSON response:', parseError);
      const responseText = await response.text();
      console.error('‚ùå AnalysisService: Raw response:', responseText);
      const errorMessage = parseError instanceof Error ? parseError.message : 'Unknown parsing error';
      throw new Error(`Failed to parse analysis response: ${errorMessage}`);
    }

    console.log('‚úÖ AnalysisService: API response parsed successfully', {
      hasId: !!result.id,
      hasJobData: !!result.jobData,
      hasGhostProbability: typeof result.ghostProbability === 'number',
      resultKeys: result ? Object.keys(result) : [],
      ghostProbValue: result.ghostProbability,
      jobDataKeys: result.jobData ? Object.keys(result.jobData) : []
    });

    // Validate critical fields
    if (!result.id) {
      console.warn('‚ö†Ô∏è AnalysisService: Response missing id field');
    }
    if (typeof result.ghostProbability !== 'number') {
      console.warn('‚ö†Ô∏è AnalysisService: Response missing or invalid ghostProbability:', result.ghostProbability);
    }

    return result;
  }

  static async uploadBulkAnalysis(file: File): Promise<BulkAnalysisJob> {
    const formData = new FormData()
    formData.append('file', file)

    const response = await fetch(`${this.API_BASE}/bulk-analyze`, {
      method: 'POST',
      body: formData,
    })

    if (!response.ok) {
      throw new Error(`Bulk analysis upload failed: ${response.statusText}`)
    }

    return response.json()
  }

  static async getBulkAnalysisStatus(jobId: string): Promise<BulkAnalysisJob> {
    const response = await fetch(`${this.API_BASE}/bulk-analyze/${jobId}`)

    if (!response.ok) {
      throw new Error(`Failed to get bulk analysis status: ${response.statusText}`)
    }

    return response.json()
  }

  static async getAnalysisHistory(): Promise<{
    analyses: any[];
    stats: { total: number; highRisk: number; mediumRisk: number; lowRisk: number };
  }> {
    try {
      const response = await fetch(`${this.API_BASE}/analysis-history`, {
        method: 'GET',
        headers: {
          'Content-Type': 'application/json',
        },
      })

      if (!response.ok) {
        throw new Error(`Failed to fetch analysis history: ${response.statusText}`)
      }

      return response.json()
    } catch (error) {
      console.warn('API call failed, returning mock data for development:', error)
      
      // Return mock data for development
      const mockAnalyses = [
        {
          id: "mock-1",
          jobUrl: "https://www.linkedin.com/jobs/view/4283562303",
          jobData: {
            title: "Senior Software Engineer",
            company: "Tech Corp",
            description: "We are looking for a senior software engineer...",
            location: "San Francisco, CA",
            remote: false
          },
          title: "Senior Software Engineer",
          company: "Tech Corp", 
          location: "San Francisco, CA",
          remote: false,
          ghostProbability: 0.15,
          riskLevel: "low",
          riskFactors: [],
          keyFactors: ["Recent posting", "Detailed requirements", "Clear job description"],
          timestamp: new Date(Date.now() - 86400000), // 1 day ago
          isNewContribution: false,
          metadata: {
            storage: 'mock',
            version: '1.0',
            sourceType: 'linkedin',
            analysisDate: new Date(Date.now() - 86400000),
            jobListingId: 'mock-job-1',
            sourceId: 'mock-source-1',
            algorithmAssessment: {
              ghostProbability: 15,
              modelConfidence: "High (95%)",
              assessmentText: "This job posting shows strong indicators of being legitimate with clear requirements and recent posting activity."
            },
            riskFactorsAnalysis: {
              warningSignsCount: 0,
              warningSignsTotal: 8,
              riskFactors: [],
              positiveIndicators: [
                {
                  type: "posting_freshness",
                  description: "Recently posted within 48 hours",
                  impact: "Positive"
                },
                {
                  type: "requirements_detail",
                  description: "Detailed technical requirements specified",
                  impact: "Positive"
                }
              ]
            },
            recommendation: {
              action: "Apply",
              message: "This appears to be a legitimate opportunity worth pursuing. The job posting shows positive indicators and minimal risk factors.",
              confidence: "High"
            },
            analysisDetails: {
              analysisId: "mock-analysis-1",
              modelVersion: "v0.1.0",
              processingTimeMs: 850,
              analysisDate: new Date(Date.now() - 86400000).toISOString(),
              algorithmType: "ensemble_classifier",
              platform: "linkedin"
            }
          }
        },
        {
          id: "mock-2", 
          jobUrl: "https://job-boards.greenhouse.io/company/jobs/123456",
          jobData: {
            title: "Product Manager",
            company: "StartupCo",
            description: "Join our amazing team...",
            location: "Remote",
            remote: true
          },
          title: "Product Manager",
          company: "StartupCo",
          location: "Remote", 
          remote: true,
          ghostProbability: 0.72,
          riskLevel: "high",
          riskFactors: ["Vague job description", "Posted for 60+ days", "Unusual posting frequency"],
          keyFactors: ["Remote position", "Startup company"],
          timestamp: new Date(Date.now() - 172800000), // 2 days ago
          isNewContribution: false,
          metadata: {
            storage: 'mock',
            version: '1.0', 
            sourceType: 'greenhouse',
            analysisDate: new Date(Date.now() - 172800000),
            jobListingId: 'mock-job-2',
            sourceId: 'mock-source-2',
            algorithmAssessment: {
              ghostProbability: 72,
              modelConfidence: "Medium (78%)",
              assessmentText: "This job posting shows several warning signs including vague descriptions and prolonged posting duration."
            },
            riskFactorsAnalysis: {
              warningSignsCount: 3,
              warningSignsTotal: 8,
              riskFactors: [
                {
                  type: "description_quality",
                  description: "Job description lacks specific requirements",
                  impact: "High"
                },
                {
                  type: "posting_duration", 
                  description: "Posted for over 60 days",
                  impact: "Medium"
                }
              ],
              positiveIndicators: [
                {
                  type: "platform_reputation",
                  description: "Posted on reputable job platform",
                  impact: "Low"
                }
              ]
            },
            recommendation: {
              action: "Research Further",
              message: "Exercise caution with this posting. Research the company thoroughly and look for additional verification before applying.",
              confidence: "Medium"
            },
            analysisDetails: {
              analysisId: "mock-analysis-2",
              modelVersion: "v0.1.0", 
              processingTimeMs: 920,
              analysisDate: new Date(Date.now() - 172800000).toISOString(),
              algorithmType: "ensemble_classifier",
              platform: "greenhouse"
            }
          }
        }
      ]

      return {
        analyses: mockAnalyses,
        stats: {
          total: mockAnalyses.length,
          highRisk: mockAnalyses.filter(a => a.ghostProbability >= 0.67).length,
          mediumRisk: mockAnalyses.filter(a => a.ghostProbability >= 0.34 && a.ghostProbability < 0.67).length,
          lowRisk: mockAnalyses.filter(a => a.ghostProbability < 0.34).length
        }
      }
    }
  }

  static async exportAnalysisResults(
    analysisIds: string[],
    format: 'csv' | 'pdf'
  ): Promise<Blob> {
    const response = await fetch(`${this.API_BASE}/export`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ analysisIds, format }),
    })

    if (!response.ok) {
      throw new Error(`Export failed: ${response.statusText}`)
    }

    return response.blob()
  }

  static async extractJobData(jobUrl: string): Promise<{title: string, company: string, location?: string, remoteFlag?: boolean, postedAt?: Date, parsingMetadata?: any}> {
    try {
      // Use the new parser registry system
      const parserRegistry = ParserRegistry.getInstance()
      const parsedJob = await parserRegistry.parseJob(jobUrl)
      
      return {
        title: parsedJob.title,
        company: parsedJob.company,
        location: parsedJob.location,
        remoteFlag: parsedJob.remoteFlag,
        postedAt: parsedJob.postedAt,
        parsingMetadata: {
          parserUsed: parsedJob.metadata.parserUsed,
          parserVersion: parsedJob.metadata.parserVersion,
          extractionMethod: parsedJob.metadata.extractionMethod,
          confidence: parsedJob.metadata.confidence,
          validationResults: parsedJob.metadata.validationResults,
          extractionTimestamp: parsedJob.metadata.extractionTimestamp,
          rawData: parsedJob.metadata.rawData
        }
      }
    } catch (error) {
      console.error('Job extraction error:', error)
      
      // Fallback to legacy system if new parser fails
      try {
        const legacyResult = await this.extractJobDataLegacy(jobUrl)
        return {
          title: legacyResult.title,
          company: legacyResult.company,
          location: undefined,
          remoteFlag: false,
          postedAt: undefined,
          parsingMetadata: {
            parserUsed: 'LegacyParser',
            parserVersion: '1.0.0',
            extractionMethod: 'manual_fallback',
            confidence: { overall: 0.3, title: 0.3, company: 0.3 },
            validationResults: [],
            extractionTimestamp: new Date(),
            rawData: {}
          }
        }
      } catch {
        return {
          title: 'Unknown Position',
          company: 'Unknown Company',
          location: undefined,
          remoteFlag: false,
          postedAt: undefined
        }
      }
    }
  }

  // Legacy extraction method for fallback
  private static async extractJobDataLegacy(jobUrl: string): Promise<{title: string, company: string}> {
    try {
      const url = new URL(jobUrl)
      const hostname = url.hostname.toLowerCase().replace('www.', '')
      
      // Greenhouse (job-boards.greenhouse.io/company/jobs/id)
      if (hostname.includes('greenhouse')) {
        return this.extractGreenhouseJob(url, jobUrl)
      }
      
      // LinkedIn
      if (hostname.includes('linkedin')) {
        return this.extractLinkedInJob(url, jobUrl)
      }
      
      // Company career pages
      if (hostname.includes('careers.') || url.pathname.includes('/careers') || url.pathname.includes('/jobs')) {
        return this.extractCompanyCareerPageJob(url, jobUrl)
      }
      
      // Major job boards
      if (hostname.includes('indeed') || hostname.includes('glassdoor') || hostname.includes('monster')) {
        return this.extractJobBoardJob(url, jobUrl)
      }
      
      // Generic fallback - try to scrape any job posting
      return this.extractGenericJob(url, jobUrl)
    } catch (error) {
      console.error('Legacy job extraction error:', error)
      return {
        title: 'Unknown Position',
        company: 'Unknown Company'
      }
    }
  }

  private static async extractGreenhouseJob(url: URL, jobUrl: string): Promise<{title: string, company: string}> {
    const pathParts = url.pathname.split('/').filter(part => part.length > 0)
    const company = pathParts[0] || 'Unknown Company'
    
    try {
      const response = await fetch(`https://api.allorigins.win/get?url=${encodeURIComponent(jobUrl)}`)
      const data = await response.json()
      const html = data.contents
      
      const titleMatch = html.match(/<title[^>]*>([^<]+)</i) || 
                       html.match(/<h1[^>]*>([^<]+)</i) ||
                       html.match(/class="[^"]*title[^"]*"[^>]*>([^<]+)/i)
      
      let title = titleMatch ? titleMatch[1].trim() : 'Unknown Position'
      title = title.replace(/\s*-\s*(Contentful|at\s+\w+).*$/i, '').trim()
      
      return {
        title: title,
        company: company.charAt(0).toUpperCase() + company.slice(1)
      }
    } catch (fetchError) {
      return {
        title: 'Unknown Position',
        company: company.charAt(0).toUpperCase() + company.slice(1)
      }
    }
  }

  private static async extractLinkedInJob(_url: URL, jobUrl: string): Promise<{title: string, company: string}> {
    try {
      // LinkedIn requires different approach due to dynamic content
      const response = await fetch(`https://api.allorigins.win/get?url=${encodeURIComponent(jobUrl)}`)
      const data = await response.json()
      const html = data.contents
      
      // Extract title from LinkedIn page structure
      const titleMatch = html.match(/<title[^>]*>([^<]+)</i)
      let title = 'Unknown Position'
      let company = 'Unknown Company'
      
      if (titleMatch) {
        const fullTitle = titleMatch[1].trim()
        
        // Try multiple LinkedIn title formats:
        // 1. "Job Title - Company Name | LinkedIn"
        // 2. "Job Title at Company Name | LinkedIn" 
        // 3. "Company Name: Job Title | LinkedIn"
        
        if (fullTitle.includes(' - ') && fullTitle.includes(' | LinkedIn')) {
          const parts = fullTitle.replace(' | LinkedIn', '').split(' - ')
          if (parts.length >= 2) {
            title = parts[0].trim()
            company = parts[1].trim()
          }
        } else if (fullTitle.includes(' at ') && fullTitle.includes(' | LinkedIn')) {
          const parts = fullTitle.replace(' | LinkedIn', '').split(' at ')
          if (parts.length >= 2) {
            title = parts[0].trim()
            company = parts[1].trim()
          }
        } else if (fullTitle.includes(': ') && fullTitle.includes(' | LinkedIn')) {
          const parts = fullTitle.replace(' | LinkedIn', '').split(': ')
          if (parts.length >= 2) {
            company = parts[0].trim()
            title = parts[1].trim()
          }
        }
        
        // Enhanced fallback: try to extract from JSON-LD, meta tags, or hiring patterns
        if (company === 'Unknown Company') {
          // Try structured data patterns
          const structuredDataPatterns = [
            /"hiringOrganization"[^}]*"name"\s*:\s*"([^"]+)"/i,
            /property="og:site_name"[^>]*content="([^"]+)"/i,
            /"companyName"\s*:\s*"([^"]+)"/i,
            /"company"\s*:\s*"([^"]+)"/i
          ]
          
          for (const pattern of structuredDataPatterns) {
            const match = html.match(pattern)
            if (match && match[1] && match[1].trim() !== 'LinkedIn') {
              company = match[1].trim()
              break
            }
          }
          
          // Try hiring patterns if still no company found
          if (company === 'Unknown Company') {
            const hiringPatterns = [
              /(.+?)\s+(?:is\s+)?hiring\s+/i,
              /join\s+(.+?)\s+(?:team|as|and)/i,
              /careers?\s+at\s+(.+?)[\s<]/i
            ]
            
            for (const pattern of hiringPatterns) {
              const match = fullTitle.match(pattern)
              if (match && match[1] && match[1].trim().length > 2) {
                const potentialCompany = match[1].trim()
                // Avoid generic terms
                if (!['the', 'our', 'this', 'that', 'company', 'organization'].includes(potentialCompany.toLowerCase())) {
                  company = potentialCompany
                  break
                }
              }
            }
          }
        }
      }
      
      return { title, company }
    } catch (error) {
      return {
        title: 'Unknown Position', 
        company: 'Unknown Company'
      }
    }
  }

  private static async extractCompanyCareerPageJob(url: URL, jobUrl: string): Promise<{title: string, company: string}> {
    try {
      const response = await fetch(`https://api.allorigins.win/get?url=${encodeURIComponent(jobUrl)}`)
      const data = await response.json()
      const html = data.contents
      
      // Common patterns for career pages
      const titlePatterns = [
        /<title[^>]*>([^<]+)</i,
        /<h1[^>]*class="[^"]*(?:job-title|position|role)[^"]*"[^>]*>([^<]+)</i,
        /<h1[^>]*>([^<]+)</i,
        /class="[^"]*(?:job-title|position|role)[^"]*"[^>]*>([^<]+)/i
      ]
      
      let title = 'Unknown Position'
      for (const pattern of titlePatterns) {
        const match = html.match(pattern)
        if (match) {
          title = match[1].trim()
          // Clean up common suffixes
          title = title.replace(/\s*[-‚Äì]\s*.*$/, '').trim()
          break
        }
      }
      
      // Extract company name from hostname or page content
      let company = url.hostname.replace('careers.', '').replace('.com', '').split('.')[0]
      company = company.charAt(0).toUpperCase() + company.slice(1)
      
      // Try to find company name in structured data or meta tags
      const companyPatterns = [
        /"name"\s*:\s*"([^"]+)"/i,  // JSON-LD company name
        /property="og:site_name"[^>]*content="([^"]+)"/i,  // Open Graph
        /<title[^>]*>([^<]*?)\s*[-|]\s*Careers/i,  // Title with "Careers"
        /class="[^"]*company[^"]*"[^>]*>([^<]+)</i  // Company class
      ]
      
      for (const pattern of companyPatterns) {
        const match = html.match(pattern)
        if (match && match[1].trim().length > 1 && !match[1].includes('{')) {
          const extractedCompany = match[1].trim()
          if (extractedCompany.toLowerCase() !== 'careers') {
            company = extractedCompany
            break
          }
        }
      }
      
      return { title, company }
    } catch (error) {
      const company = url.hostname.replace('careers.', '').replace('.com', '').split('.')[0]
      return {
        title: 'Unknown Position',
        company: company.charAt(0).toUpperCase() + company.slice(1)
      }
    }
  }

  private static async extractJobBoardJob(url: URL, jobUrl: string): Promise<{title: string, company: string}> {
    try {
      const response = await fetch(`https://api.allorigins.win/get?url=${encodeURIComponent(jobUrl)}`)
      const data = await response.json()
      const html = data.contents
      
      const titleMatch = html.match(/<title[^>]*>([^<]+)</i) || 
                       html.match(/<h1[^>]*>([^<]+)</i)
      
      let title = titleMatch ? titleMatch[1].trim() : 'Unknown Position'
      title = title.replace(/\s*[-‚Äì]\s*.*$/, '').trim()
      
      const platform = url.hostname.includes('indeed') ? 'Indeed' :
                      url.hostname.includes('glassdoor') ? 'Glassdoor' :
                      url.hostname.includes('monster') ? 'Monster' : 'Job Board'
      
      return {
        title: title,
        company: platform
      }
    } catch (error) {
      return {
        title: 'Unknown Position',
        company: 'Job Board'
      }
    }
  }

  private static async extractGenericJob(url: URL, jobUrl: string): Promise<{title: string, company: string}> {
    try {
      const response = await fetch(`https://api.allorigins.win/get?url=${encodeURIComponent(jobUrl)}`)
      const data = await response.json()
      const html = data.contents
      
      const titleMatch = html.match(/<title[^>]*>([^<]+)</i) || 
                       html.match(/<h1[^>]*>([^<]+)</i)
      
      const title = titleMatch ? titleMatch[1].trim() : 'Unknown Position'
      const company = url.hostname.replace('www.', '').split('.')[0] || 'Unknown Company'
      
      return {
        title: title,
        company: company.charAt(0).toUpperCase() + company.slice(1)
      }
    } catch (error) {
      return {
        title: 'Unknown Position',
        company: 'Unknown Company'
      }
    }
  }

  static async extractJobDataFromPDF(file: File, onProgress?: (stage: string, progress: number) => void): Promise<{title: string, company: string, content: string, sourceUrl?: string, confidence?: number, parsingMetadata?: any}> {
    try {
      // Import the PDF parsing services dynamically to avoid bundling issues
      const { PDFParsingService } = await import('./parsing/PDFParsingService')
      const { PDFWebLLMIntegration } = await import('./parsing/PDFWebLLMIntegration')
      
      console.log('üîÑ Starting enhanced PDF parsing with WebLLM integration...')
      
      // Phase 1: Extract raw data from PDF
      onProgress?.('Extracting PDF content', 30)
      const pdfService = PDFParsingService.getInstance()
      const pdfData = await pdfService.extractJobData(file, {
        onProgress: (stage, progress) => {
          // Map PDF extraction progress to first 60% of total progress
          const mappedProgress = 30 + (progress * 0.3)
          onProgress?.(stage, mappedProgress)
        },
        includeRawText: true
      })
      
      console.log('‚úÖ PDF extraction completed, starting WebLLM validation...')
      
      // Phase 2: Validate through WebLLM pipeline (Phase 3.1 implementation)
      onProgress?.('Validating job data with AI', 70)
      
      const webllmResult = await PDFWebLLMIntegration.validatePDFJobData({
        pdfJobData: pdfData,
        sourceUrl: pdfData.sourceUrl,
        rawTextContent: pdfData.rawTextContent || ''
      })
      
      // Provide user feedback on validation mode
      if (webllmResult.webllmValidation.validated) {
        onProgress?.('AI validation completed successfully', 85)
      } else {
        onProgress?.('Using enhanced PDF validation mode', 85)
      }
      
      onProgress?.('Finalizing enhanced analysis', 90)
      
      console.log('üéØ Enhanced PDF analysis completed:', {
        title: webllmResult.validatedJobData.title,
        company: webllmResult.validatedJobData.company,
        confidence: webllmResult.validatedJobData.confidence.overall,
        webllmValidated: webllmResult.webllmValidation.validated,
        legitimacyIndicators: webllmResult.enhancedMetadata.legitimacyIndicators.length,
        riskFactors: webllmResult.enhancedMetadata.riskFactors.length
      })
      
      // Convert to expected format with enhanced data
      return {
        title: webllmResult.validatedJobData.title,
        company: webllmResult.validatedJobData.company,
        content: webllmResult.validatedJobData.description,
        sourceUrl: pdfData.sourceUrl,
        confidence: webllmResult.validatedJobData.confidence.overall,
        parsingMetadata: {
          ...pdfData.parsingMetadata,
          // Add WebLLM enhancement metadata
          extractionMethod: webllmResult.enhancedMetadata.extractionMethod,
          webllmValidated: webllmResult.webllmValidation.validated,
          webllmConfidence: webllmResult.enhancedMetadata.webllmConfidence,
          validationTime: webllmResult.enhancedMetadata.validationTime,
          thoughtProcess: webllmResult.enhancedMetadata.thoughtProcess,
          legitimacyIndicators: webllmResult.enhancedMetadata.legitimacyIndicators,
          riskFactors: webllmResult.enhancedMetadata.riskFactors,
          // Enhanced confidence breakdown
          confidenceBreakdown: webllmResult.validatedJobData.confidence
        }
      }
    } catch (error) {
      console.error('üö® PDF parsing failed - STOPPING analysis workflow:', error)
      
      // CRITICAL: Do NOT proceed with analysis when PDF parsing fails
      // This prevents fake analysis results from being generated and stored
      throw new Error(`PDF parsing failed - cannot analyze job posting: ${error instanceof Error ? error.message : 'Unknown error'}`)
    }
  }


  static async extractJobsFromLinkedInSearch(searchUrl: string): Promise<string[]> {
    try {
      // Extract job IDs from LinkedIn search URL
      const url = new URL(searchUrl)
      const jobIds: string[] = []
      
      // Parse currentJobId parameter
      const currentJobId = url.searchParams.get('currentJobId')
      if (currentJobId) {
        jobIds.push(`https://www.linkedin.com/jobs/view/${currentJobId}`)
      }
      
      // For demo purposes, simulate extracting multiple job IDs from search results
      // In production, this would scrape the LinkedIn search results page
      const mockJobIds = [
        '4283562303', '4281730064', '4281723876', '4283559564', 
        '4283562302', '4267431281', '4276824745', '4268337639', '4268938377'
      ]
      
      mockJobIds.forEach(id => {
        jobIds.push(`https://www.linkedin.com/jobs/view/${id}`)
      })
      
      return jobIds.slice(0, 10) // Limit to first 10 results
    } catch (error) {
      console.error('LinkedIn search extraction error:', error)
      return []
    }
  }

  static async extractJobsFromCareerSite(careerSiteUrl: string): Promise<string[]> {
    try {
      // Crawl career site for job postings
      const response = await fetch(`https://api.allorigins.win/get?url=${encodeURIComponent(careerSiteUrl)}`)
      const data = await response.json()
      const html = data.contents
      
      const url = new URL(careerSiteUrl)
      const baseUrl = `${url.protocol}//${url.hostname}`
      
      // Common patterns for job links on career pages
      const linkPatterns = [
        /href="([^"]*(?:job|position|career|role)[^"]*\d+[^"]*)"/gi,
        /href="([^"]*\/jobs\/[^"]*\d+[^"]*)"/gi,
        /href="([^"]*\/careers\/[^"]*\d+[^"]*)"/gi
      ]
      
      const jobUrls = new Set<string>()
      
      for (const pattern of linkPatterns) {
        let match
        while ((match = pattern.exec(html)) !== null) {
          let jobUrl = match[1]
          
          // Convert relative URLs to absolute
          if (jobUrl.startsWith('/')) {
            jobUrl = baseUrl + jobUrl
          } else if (!jobUrl.startsWith('http')) {
            jobUrl = baseUrl + '/' + jobUrl
          }
          
          // Validate it looks like a job posting URL
          if (jobUrl.includes('job') || jobUrl.includes('position') || jobUrl.includes('career')) {
            jobUrls.add(jobUrl)
          }
        }
      }
      
      return Array.from(jobUrls).slice(0, 20) // Limit to first 20 results
    } catch (error) {
      console.error('Career site crawling error:', error)
      return []
    }
  }

  static mockAnalyzeJob(_jobUrl: string): Promise<AnalysisResult> {
    return new Promise((resolve) => {
      setTimeout(() => {
        resolve({
          id: Math.random().toString(36).substr(2, 9),
          ghostProbability: Math.random(),
          riskLevel: Math.random() > 0.5 ? 'high' : 'low',
          riskFactors: [
            'Job has been posted for 45+ days',
            'Description contains minimal specific requirements',
            'Company has unusual posting frequency'
          ],
          keyFactors: [
            'LinkedIn posting',
            'Remote position'
          ],
          metadata: {
            storage: 'mock',
            version: 'v0.1.7',
            cached: false,
            analysisDate: new Date().toISOString()
          }
        })
      }, 1500)
    })
  }

  /**
   * Proactively trigger learning when parsing fails
   */
  private static async triggerLearningForFailure(
    jobUrl: string, 
    failedResult: { title: string, company: string, location?: string },
    originalError: Error
  ): Promise<void> {
    try {
      console.log(`üîÑ Triggering proactive learning for failed parse: ${jobUrl}`)

      // Try to fetch HTML for learning analysis
      let html = ''
      try {
        const response = await fetch(`https://api.allorigins.win/get?url=${encodeURIComponent(jobUrl)}`)
        const data = await response.json()
        html = data.contents || ''
      } catch (htmlError) {
        console.warn('Could not fetch HTML for learning analysis:', htmlError)
      }

      // Call our learning API endpoint (consolidated into parse-preview)
      const response = await fetch('/api/parse-preview?mode=learning', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          url: jobUrl,
          html,
          failedResult,
          userAgent: typeof navigator !== 'undefined' ? navigator.userAgent : 'Server',
          originalError: {
            message: originalError.message,
            stack: originalError.stack
          }
        })
      })

      if (response.ok) {
        const result = await response.json()
        console.log(`‚úÖ Proactive learning completed:`, result)
        
        if (result.hasImprovements) {
          console.log(`üéì Learning found ${result.improvementsCount} improvements:`, result.improvements)
          
          // You could potentially update the UI here to show the improved results
          // This would require exposing a callback or event system
        }
      } else {
        console.warn('Learning API call failed:', response.status, response.statusText)
      }

    } catch (error) {
      console.error('Proactive learning trigger failed:', error)
      // Don't throw - we don't want learning failures to break the main flow
    }
  }

  /**
   * Check if parsing result indicates low quality and should trigger learning
   */
  private static shouldTriggerLearning(
    result: { title: string, company: string, location?: string }
  ): boolean {
    return (
      result.title === 'Unknown Position' ||
      result.company === 'Unknown Company' ||
      result.title.length < 5 ||
      result.company.length < 3
    )
  }

  /**
   * Enhanced extraction with proactive learning
   */
  static async extractJobDataWithLearning(jobUrl: string): Promise<{
    title: string, 
    company: string, 
    location?: string, 
    remoteFlag?: boolean, 
    postedAt?: Date, 
    parsingMetadata?: any,
    learningApplied?: boolean,
    improvements?: string[]
  }> {
    try {
      // First, try standard extraction
      const standardResult = await this.extractJobData(jobUrl)
      
      // Check if result is poor quality
      if (this.shouldTriggerLearning(standardResult)) {
        console.log('üîç Poor quality parsing detected, applying real-time learning...')
        
        // Trigger learning and get improvements
        await this.triggerLearningForFailure(
          jobUrl, 
          {
            title: standardResult.title,
            company: standardResult.company,
            location: standardResult.location
          },
          new Error('Poor quality parsing result')
        )
        
        // Return enhanced result with learning metadata
        return {
          ...standardResult,
          learningApplied: true,
          improvements: [] // This would be populated by the learning service
        }
      }
      
      return {
        ...standardResult,
        learningApplied: false
      }
    } catch (error) {
      console.error('Enhanced extraction failed:', error)
      throw error
    }
  }
}